data = readmatrix('swedish_insurance.csv.xlsx');
X = data(:,1);
y = data(:,2);
m = length(y);
X = (X-mean(X))/std(X);
X_b = [ones(m,1),X];
theta = zeros(2,1);
alpha = 0.01;
n = 1000;
history = zeros(n,1);
for i = 1:n
 prediction = X_b*theta;
 errors = prediction - y;
 gradient = (1/m)*(X_b'*errors);
 theta = theta - alpha*gradient;
 history(i) = (1/(2*m))*sum(errors.^2);
end
fprintf('Slope: %.4f',theta(2));
fprintf('Intercept: %.4f',theta(1));
figure;
plot(1:n,history,'b-','LineWidth',2);
xlabel('Iteration');
ylabel('Cost');
title('Convergence of gradient descent');
grid on;
x = 6;
x_new = (x - mean(data(:,1)))/std(data(:,1));
x_new = [1,x_new];
y_new_pred = x_new*theta;
fprintf('X = %.2f then Y = %.2f',x,y_new_pred);
figure;
plot(X,y,'bo','MarkerSize',7);
hold on;
plot(X,X_b*theta,'r-','LineWidth',3);
plot(x_new(2),y_new_pred,'gs','MarkerSize',7,'MarkerFaceColor','g');
xlabel('Features');
ylabel('Targets');
title('Linear Regression using Gradient Descent');
legend('Training Data','Regression Line','Test Data');
grid on;